AdaptiveSparkPlan isFinalPlan=true
+- == Final Plan ==
   *(14) HashAggregate(keys=[], functions=[count(1)], output=[count(1)#19490L])
   +- ShuffleQueryStage 6
      +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#206802]
         +- *(13) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#19493L])
            +- *(13) Project
               +- *(13) SortMergeJoin [ss_store_sk#259], [s_store_sk#712], Inner
                  :- *(11) Sort [ss_store_sk#259 ASC NULLS FIRST], false, 0
                  :  +- AQEShuffleRead coalesced
                  :     +- ShuffleQueryStage 5
                  :        +- Exchange hashpartitioning(ss_store_sk#259, 200), ENSURE_REQUIREMENTS, [id=#206724]
                  :           +- *(10) Project [ss_store_sk#259]
                  :              +- *(10) SortMergeJoin [ss_sold_time_sk#253], [t_time_sk#456], Inner
                  :                 :- *(8) Sort [ss_sold_time_sk#253 ASC NULLS FIRST], false, 0
                  :                 :  +- AQEShuffleRead coalesced
                  :                 :     +- ShuffleQueryStage 4
                  :                 :        +- Exchange hashpartitioning(ss_sold_time_sk#253, 200), ENSURE_REQUIREMENTS, [id=#206621]
                  :                 :           +- *(7) Project [ss_sold_time_sk#253, ss_store_sk#259]
                  :                 :              +- *(7) SortMergeJoin [ss_hdemo_sk#257], [hd_demo_sk#88], Inner
                  :                 :                 :- *(5) Sort [ss_hdemo_sk#257 ASC NULLS FIRST], false, 0
                  :                 :                 :  +- AQEShuffleRead coalesced
                  :                 :                 :     +- ShuffleQueryStage 0
                  :                 :                 :        +- Exchange hashpartitioning(ss_hdemo_sk#257, 200), ENSURE_REQUIREMENTS, [id=#206275]
                  :                 :                 :           +- *(1) Filter ((isnotnull(ss_hdemo_sk#257) AND isnotnull(ss_sold_time_sk#253)) AND isnotnull(ss_store_sk#259))
                  :                 :                 :              +- *(1) ColumnarToRow
                  :                 :                 :                 +- FileScan parquet [ss_sold_time_sk#253,ss_hdemo_sk#257,ss_store_sk#259] Batched: true, DataFilters: [isnotnull(ss_hdemo_sk#257), isnotnull(ss_sold_time_sk#253), isnotnull(ss_store_sk#259)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)], ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>
                  :                 :                 +- *(6) Sort [hd_demo_sk#88 ASC NULLS FIRST], false, 0
                  :                 :                    +- AQEShuffleRead coalesced
                  :                 :                       +- ShuffleQueryStage 1
                  :                 :                          +- Exchange hashpartitioning(hd_demo_sk#88, 200), ENSURE_REQUIREMENTS, [id=#206294]
                  :                 :                             +- *(2) Project [hd_demo_sk#88]
                  :                 :                                +- *(2) Filter ((isnotnull(hd_dep_count#91) AND (hd_dep_count#91 = 5)) AND isnotnull(hd_demo_sk#88))
                  :                 :                                   +- *(2) ColumnarToRow
                  :                 :                                      +- FileScan parquet [hd_demo_sk#88,hd_dep_count#91] Batched: true, DataFilters: [isnotnull(hd_dep_count#91), (hd_dep_count#91 = 5), isnotnull(hd_demo_sk#88)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/household_demographics.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(hd_dep_count), EqualTo(hd_dep_count,5), IsNotNull(hd_demo_sk)], ReadSchema: struct<hd_demo_sk:int,hd_dep_count:int>
                  :                 +- *(9) Sort [t_time_sk#456 ASC NULLS FIRST], false, 0
                  :                    +- AQEShuffleRead coalesced
                  :                       +- ShuffleQueryStage 2
                  :                          +- Exchange hashpartitioning(t_time_sk#456, 200), ENSURE_REQUIREMENTS, [id=#206319]
                  :                             +- *(3) Project [t_time_sk#456]
                  :                                +- *(3) Filter ((((isnotnull(t_hour#459) AND isnotnull(t_minute#460)) AND (t_hour#459 = 8)) AND (t_minute#460 >= 30)) AND isnotnull(t_time_sk#456))
                  :                                   +- *(3) ColumnarToRow
                  :                                      +- FileScan parquet [t_time_sk#456,t_hour#459,t_minute#460] Batched: true, DataFilters: [isnotnull(t_hour#459), isnotnull(t_minute#460), (t_hour#459 = 8), (t_minute#460 >= 30), isnotnul..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/time_dim.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,8), GreaterThanOrEqual(t_minute,30), IsNo..., ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>
                  +- *(12) Sort [s_store_sk#712 ASC NULLS FIRST], false, 0
                     +- AQEShuffleRead coalesced
                        +- ShuffleQueryStage 3
                           +- Exchange hashpartitioning(s_store_sk#712, 200), ENSURE_REQUIREMENTS, [id=#206344]
                              +- *(4) Project [s_store_sk#712]
                                 +- *(4) Filter ((isnotnull(s_store_name#717) AND (s_store_name#717 = ese)) AND isnotnull(s_store_sk#712))
                                    +- *(4) ColumnarToRow
                                       +- FileScan parquet [s_store_sk#712,s_store_name#717] Batched: true, DataFilters: [isnotnull(s_store_name#717), (s_store_name#717 = ese), isnotnull(s_store_sk#712)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_name), EqualTo(s_store_name,ese), IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_store_name:string>
+- == Initial Plan ==
   HashAggregate(keys=[], functions=[count(1)], output=[count(1)#19490L])
   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#206210]
      +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#19493L])
         +- Project
            +- SortMergeJoin [ss_store_sk#259], [s_store_sk#712], Inner
               :- Sort [ss_store_sk#259 ASC NULLS FIRST], false, 0
               :  +- Exchange hashpartitioning(ss_store_sk#259, 200), ENSURE_REQUIREMENTS, [id=#206202]
               :     +- Project [ss_store_sk#259]
               :        +- SortMergeJoin [ss_sold_time_sk#253], [t_time_sk#456], Inner
               :           :- Sort [ss_sold_time_sk#253 ASC NULLS FIRST], false, 0
               :           :  +- Exchange hashpartitioning(ss_sold_time_sk#253, 200), ENSURE_REQUIREMENTS, [id=#206194]
               :           :     +- Project [ss_sold_time_sk#253, ss_store_sk#259]
               :           :        +- SortMergeJoin [ss_hdemo_sk#257], [hd_demo_sk#88], Inner
               :           :           :- Sort [ss_hdemo_sk#257 ASC NULLS FIRST], false, 0
               :           :           :  +- Exchange hashpartitioning(ss_hdemo_sk#257, 200), ENSURE_REQUIREMENTS, [id=#206186]
               :           :           :     +- Filter ((isnotnull(ss_hdemo_sk#257) AND isnotnull(ss_sold_time_sk#253)) AND isnotnull(ss_store_sk#259))
               :           :           :        +- FileScan parquet [ss_sold_time_sk#253,ss_hdemo_sk#257,ss_store_sk#259] Batched: true, DataFilters: [isnotnull(ss_hdemo_sk#257), isnotnull(ss_sold_time_sk#253), isnotnull(ss_store_sk#259)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_hdemo_sk), IsNotNull(ss_sold_time_sk), IsNotNull(ss_store_sk)], ReadSchema: struct<ss_sold_time_sk:int,ss_hdemo_sk:int,ss_store_sk:int>
               :           :           +- Sort [hd_demo_sk#88 ASC NULLS FIRST], false, 0
               :           :              +- Exchange hashpartitioning(hd_demo_sk#88, 200), ENSURE_REQUIREMENTS, [id=#206187]
               :           :                 +- Project [hd_demo_sk#88]
               :           :                    +- Filter ((isnotnull(hd_dep_count#91) AND (hd_dep_count#91 = 5)) AND isnotnull(hd_demo_sk#88))
               :           :                       +- FileScan parquet [hd_demo_sk#88,hd_dep_count#91] Batched: true, DataFilters: [isnotnull(hd_dep_count#91), (hd_dep_count#91 = 5), isnotnull(hd_demo_sk#88)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/household_demographics.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(hd_dep_count), EqualTo(hd_dep_count,5), IsNotNull(hd_demo_sk)], ReadSchema: struct<hd_demo_sk:int,hd_dep_count:int>
               :           +- Sort [t_time_sk#456 ASC NULLS FIRST], false, 0
               :              +- Exchange hashpartitioning(t_time_sk#456, 200), ENSURE_REQUIREMENTS, [id=#206195]
               :                 +- Project [t_time_sk#456]
               :                    +- Filter ((((isnotnull(t_hour#459) AND isnotnull(t_minute#460)) AND (t_hour#459 = 8)) AND (t_minute#460 >= 30)) AND isnotnull(t_time_sk#456))
               :                       +- FileScan parquet [t_time_sk#456,t_hour#459,t_minute#460] Batched: true, DataFilters: [isnotnull(t_hour#459), isnotnull(t_minute#460), (t_hour#459 = 8), (t_minute#460 >= 30), isnotnul..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/time_dim.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(t_hour), IsNotNull(t_minute), EqualTo(t_hour,8), GreaterThanOrEqual(t_minute,30), IsNo..., ReadSchema: struct<t_time_sk:int,t_hour:int,t_minute:int>
               +- Sort [s_store_sk#712 ASC NULLS FIRST], false, 0
                  +- Exchange hashpartitioning(s_store_sk#712, 200), ENSURE_REQUIREMENTS, [id=#206203]
                     +- Project [s_store_sk#712]
                        +- Filter ((isnotnull(s_store_name#717) AND (s_store_name#717 = ese)) AND isnotnull(s_store_sk#712))
                           +- FileScan parquet [s_store_sk#712,s_store_name#717] Batched: true, DataFilters: [isnotnull(s_store_name#717), (s_store_name#717 = ese), isnotnull(s_store_sk#712)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(s_store_name), EqualTo(s_store_name,ese), IsNotNull(s_store_sk)], ReadSchema: struct<s_store_sk:int,s_store_name:string>
