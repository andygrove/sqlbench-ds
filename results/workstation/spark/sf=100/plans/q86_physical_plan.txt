AdaptiveSparkPlan isFinalPlan=true
+- == Final Plan ==
   TakeOrderedAndProject(limit=100, orderBy=[lochierarchy#21239 DESC NULLS LAST,CASE WHEN (lochierarchy#21239 = 0) THEN i_category#21248 END ASC NULLS FIRST,rank_within_parent#21240 ASC NULLS FIRST], output=[total_sum#21238,i_category#21248,i_class#21249,lochierarchy#21239,rank_within_parent#21240])
   +- *(12) Project [total_sum#21238, i_category#21248, i_class#21249, lochierarchy#21239, rank_within_parent#21240]
      +- Window [rank(_w3#21264) windowspecdefinition(_w1#21262, _w2#21263, _w3#21264 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#21240], [_w1#21262, _w2#21263], [_w3#21264 DESC NULLS LAST]
         +- *(11) Sort [_w1#21262 ASC NULLS FIRST, _w2#21263 ASC NULLS FIRST, _w3#21264 DESC NULLS LAST], false, 0
            +- AQEShuffleRead coalesced
               +- ShuffleQueryStage 5
                  +- Exchange hashpartitioning(_w1#21262, _w2#21263, 200), ENSURE_REQUIREMENTS, [id=#261485]
                     +- *(10) HashAggregate(keys=[i_category#21248, i_class#21249, spark_grouping_id#21247L], functions=[sum(UnscaledValue(ws_net_paid#505))], output=[total_sum#21238, i_category#21248, i_class#21249, lochierarchy#21239, _w1#21262, _w2#21263, _w3#21264])
                        +- AQEShuffleRead coalesced
                           +- ShuffleQueryStage 4
                              +- Exchange hashpartitioning(i_category#21248, i_class#21249, spark_grouping_id#21247L, 200), ENSURE_REQUIREMENTS, [id=#261430]
                                 +- *(9) HashAggregate(keys=[i_category#21248, i_class#21249, spark_grouping_id#21247L], functions=[partial_sum(UnscaledValue(ws_net_paid#505))], output=[i_category#21248, i_class#21249, spark_grouping_id#21247L, sum#21277L])
                                    +- *(9) Expand [[ws_net_paid#505, i_category#680, i_class#678, 0], [ws_net_paid#505, i_category#680, null, 1], [ws_net_paid#505, null, null, 3]], [ws_net_paid#505, i_category#21248, i_class#21249, spark_grouping_id#21247L]
                                       +- *(9) Project [ws_net_paid#505, i_category#680, i_class#678]
                                          +- *(9) SortMergeJoin [ws_item_sk#479], [i_item_sk#668], Inner
                                             :- *(7) Sort [ws_item_sk#479 ASC NULLS FIRST], false, 0
                                             :  +- AQEShuffleRead coalesced
                                             :     +- ShuffleQueryStage 3
                                             :        +- Exchange hashpartitioning(ws_item_sk#479, 200), ENSURE_REQUIREMENTS, [id=#261318]
                                             :           +- *(6) Project [ws_item_sk#479, ws_net_paid#505]
                                             :              +- *(6) SortMergeJoin [ws_sold_date_sk#476], [d_date_sk#612], Inner
                                             :                 :- *(4) Sort [ws_sold_date_sk#476 ASC NULLS FIRST], false, 0
                                             :                 :  +- AQEShuffleRead coalesced
                                             :                 :     +- ShuffleQueryStage 0
                                             :                 :        +- Exchange hashpartitioning(ws_sold_date_sk#476, 200), ENSURE_REQUIREMENTS, [id=#261041]
                                             :                 :           +- *(1) Filter (isnotnull(ws_sold_date_sk#476) AND isnotnull(ws_item_sk#479))
                                             :                 :              +- *(1) ColumnarToRow
                                             :                 :                 +- FileScan parquet [ws_sold_date_sk#476,ws_item_sk#479,ws_net_paid#505] Batched: true, DataFilters: [isnotnull(ws_sold_date_sk#476), isnotnull(ws_item_sk#479)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/web_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ws_sold_date_sk), IsNotNull(ws_item_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_item_sk:int,ws_net_paid:decimal(7,2)>
                                             :                 +- *(5) Sort [d_date_sk#612 ASC NULLS FIRST], false, 0
                                             :                    +- AQEShuffleRead coalesced
                                             :                       +- ShuffleQueryStage 1
                                             :                          +- Exchange hashpartitioning(d_date_sk#612, 200), ENSURE_REQUIREMENTS, [id=#261060]
                                             :                             +- *(2) Project [d_date_sk#612]
                                             :                                +- *(2) Filter (((isnotnull(d_month_seq#615) AND (d_month_seq#615 >= 1205)) AND (d_month_seq#615 <= 1216)) AND isnotnull(d_date_sk#612))
                                             :                                   +- *(2) ColumnarToRow
                                             :                                      +- FileScan parquet [d_date_sk#612,d_month_seq#615] Batched: true, DataFilters: [isnotnull(d_month_seq#615), (d_month_seq#615 >= 1205), (d_month_seq#615 <= 1216), isnotnull(d_da..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/date_dim.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1205), LessThanOrEqual(d_month_seq,1216),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>
                                             +- *(8) Sort [i_item_sk#668 ASC NULLS FIRST], false, 0
                                                +- AQEShuffleRead coalesced
                                                   +- ShuffleQueryStage 2
                                                      +- Exchange hashpartitioning(i_item_sk#668, 200), ENSURE_REQUIREMENTS, [id=#261083]
                                                         +- *(3) Filter isnotnull(i_item_sk#668)
                                                            +- *(3) ColumnarToRow
                                                               +- FileScan parquet [i_item_sk#668,i_class#678,i_category#680] Batched: true, DataFilters: [isnotnull(i_item_sk#668)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/item.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_class:string,i_category:string>
+- == Initial Plan ==
   TakeOrderedAndProject(limit=100, orderBy=[lochierarchy#21239 DESC NULLS LAST,CASE WHEN (lochierarchy#21239 = 0) THEN i_category#21248 END ASC NULLS FIRST,rank_within_parent#21240 ASC NULLS FIRST], output=[total_sum#21238,i_category#21248,i_class#21249,lochierarchy#21239,rank_within_parent#21240])
   +- Project [total_sum#21238, i_category#21248, i_class#21249, lochierarchy#21239, rank_within_parent#21240]
      +- Window [rank(_w3#21264) windowspecdefinition(_w1#21262, _w2#21263, _w3#21264 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank_within_parent#21240], [_w1#21262, _w2#21263], [_w3#21264 DESC NULLS LAST]
         +- Sort [_w1#21262 ASC NULLS FIRST, _w2#21263 ASC NULLS FIRST, _w3#21264 DESC NULLS LAST], false, 0
            +- Exchange hashpartitioning(_w1#21262, _w2#21263, 200), ENSURE_REQUIREMENTS, [id=#260984]
               +- HashAggregate(keys=[i_category#21248, i_class#21249, spark_grouping_id#21247L], functions=[sum(UnscaledValue(ws_net_paid#505))], output=[total_sum#21238, i_category#21248, i_class#21249, lochierarchy#21239, _w1#21262, _w2#21263, _w3#21264])
                  +- Exchange hashpartitioning(i_category#21248, i_class#21249, spark_grouping_id#21247L, 200), ENSURE_REQUIREMENTS, [id=#260981]
                     +- HashAggregate(keys=[i_category#21248, i_class#21249, spark_grouping_id#21247L], functions=[partial_sum(UnscaledValue(ws_net_paid#505))], output=[i_category#21248, i_class#21249, spark_grouping_id#21247L, sum#21277L])
                        +- Expand [[ws_net_paid#505, i_category#680, i_class#678, 0], [ws_net_paid#505, i_category#680, null, 1], [ws_net_paid#505, null, null, 3]], [ws_net_paid#505, i_category#21248, i_class#21249, spark_grouping_id#21247L]
                           +- Project [ws_net_paid#505, i_category#680, i_class#678]
                              +- SortMergeJoin [ws_item_sk#479], [i_item_sk#668], Inner
                                 :- Sort [ws_item_sk#479 ASC NULLS FIRST], false, 0
                                 :  +- Exchange hashpartitioning(ws_item_sk#479, 200), ENSURE_REQUIREMENTS, [id=#260972]
                                 :     +- Project [ws_item_sk#479, ws_net_paid#505]
                                 :        +- SortMergeJoin [ws_sold_date_sk#476], [d_date_sk#612], Inner
                                 :           :- Sort [ws_sold_date_sk#476 ASC NULLS FIRST], false, 0
                                 :           :  +- Exchange hashpartitioning(ws_sold_date_sk#476, 200), ENSURE_REQUIREMENTS, [id=#260964]
                                 :           :     +- Filter (isnotnull(ws_sold_date_sk#476) AND isnotnull(ws_item_sk#479))
                                 :           :        +- FileScan parquet [ws_sold_date_sk#476,ws_item_sk#479,ws_net_paid#505] Batched: true, DataFilters: [isnotnull(ws_sold_date_sk#476), isnotnull(ws_item_sk#479)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/web_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ws_sold_date_sk), IsNotNull(ws_item_sk)], ReadSchema: struct<ws_sold_date_sk:int,ws_item_sk:int,ws_net_paid:decimal(7,2)>
                                 :           +- Sort [d_date_sk#612 ASC NULLS FIRST], false, 0
                                 :              +- Exchange hashpartitioning(d_date_sk#612, 200), ENSURE_REQUIREMENTS, [id=#260965]
                                 :                 +- Project [d_date_sk#612]
                                 :                    +- Filter (((isnotnull(d_month_seq#615) AND (d_month_seq#615 >= 1205)) AND (d_month_seq#615 <= 1216)) AND isnotnull(d_date_sk#612))
                                 :                       +- FileScan parquet [d_date_sk#612,d_month_seq#615] Batched: true, DataFilters: [isnotnull(d_month_seq#615), (d_month_seq#615 >= 1205), (d_month_seq#615 <= 1216), isnotnull(d_da..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/date_dim.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(d_month_seq), GreaterThanOrEqual(d_month_seq,1205), LessThanOrEqual(d_month_seq,1216),..., ReadSchema: struct<d_date_sk:int,d_month_seq:int>
                                 +- Sort [i_item_sk#668 ASC NULLS FIRST], false, 0
                                    +- Exchange hashpartitioning(i_item_sk#668, 200), ENSURE_REQUIREMENTS, [id=#260973]
                                       +- Filter isnotnull(i_item_sk#668)
                                          +- FileScan parquet [i_item_sk#668,i_class#678,i_category#680] Batched: true, DataFilters: [isnotnull(i_item_sk#668)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/item.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_class:string,i_category:string>
