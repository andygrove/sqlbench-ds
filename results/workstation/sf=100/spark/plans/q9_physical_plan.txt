AdaptiveSparkPlan isFinalPlan=true
+- == Final Plan ==
   *(1) Project [CASE WHEN (Subquery subquery#3252, [id=#16807] > 409437) THEN Subquery subquery#3253, [id=#16820] ELSE Subquery subquery#3254, [id=#16833] END AS bucket1#3255, CASE WHEN (Subquery subquery#3256, [id=#16846] > 4595804) THEN Subquery subquery#3257, [id=#16859] ELSE Subquery subquery#3258, [id=#16872] END AS bucket2#3259, CASE WHEN (Subquery subquery#3260, [id=#16885] > 1333710) THEN Subquery subquery#3261, [id=#16898] ELSE Subquery subquery#3262, [id=#16911] END AS bucket3#3263, CASE WHEN (Subquery subquery#3264, [id=#16924] > 2361102) THEN Subquery subquery#3265, [id=#16937] ELSE Subquery subquery#3266, [id=#16950] END AS bucket4#3267, CASE WHEN (Subquery subquery#3268, [id=#16963] > 1517817) THEN Subquery subquery#3269, [id=#16976] ELSE Subquery subquery#3270, [id=#16989] END AS bucket5#3271]
   :  :- Subquery subquery#3252, [id=#16807]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3273L])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17212]
                  +- *(1) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3630L])
                     +- *(1) Project
                        +- *(1) Filter ((isnotnull(ss_quantity#262) AND (ss_quantity#262 >= 1)) AND (ss_quantity#262 <= 20))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#262] Batched: true, DataFilters: [isnotnull(ss_quantity#262), (ss_quantity#262 >= 1), (ss_quantity#262 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3273L])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16805]
               +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3630L])
                  +- Project
                     +- Filter ((isnotnull(ss_quantity#262) AND (ss_quantity#262 >= 1)) AND (ss_quantity#262 <= 20))
                        +- FileScan parquet [ss_quantity#262] Batched: true, DataFilters: [isnotnull(ss_quantity#262), (ss_quantity#262 >= 1), (ss_quantity#262 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int>
   :  :- Subquery subquery#3253, [id=#16820]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3320))], output=[avg(ss_ext_tax)#3275])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17180]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3320))], output=[sum#3633, count#3634L])
                     +- *(1) Project [ss_ext_tax#3320]
                        +- *(1) Filter ((isnotnull(ss_quantity#3312) AND (ss_quantity#3312 >= 1)) AND (ss_quantity#3312 <= 20))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3312,ss_ext_tax#3320] Batched: true, DataFilters: [isnotnull(ss_quantity#3312), (ss_quantity#3312 >= 1), (ss_quantity#3312 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3320))], output=[avg(ss_ext_tax)#3275])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16818]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3320))], output=[sum#3633, count#3634L])
                  +- Project [ss_ext_tax#3320]
                     +- Filter ((isnotnull(ss_quantity#3312) AND (ss_quantity#3312 >= 1)) AND (ss_quantity#3312 <= 20))
                        +- FileScan parquet [ss_quantity#3312,ss_ext_tax#3320] Batched: true, DataFilters: [isnotnull(ss_quantity#3312), (ss_quantity#3312 >= 1), (ss_quantity#3312 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
   :  :- Subquery subquery#3254, [id=#16833]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3345))], output=[avg(ss_net_paid)#3277])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17168]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3345))], output=[sum#3637, count#3638L])
                     +- *(1) Project [ss_net_paid#3345]
                        +- *(1) Filter ((isnotnull(ss_quantity#3335) AND (ss_quantity#3335 >= 1)) AND (ss_quantity#3335 <= 20))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3335,ss_net_paid#3345] Batched: true, DataFilters: [isnotnull(ss_quantity#3335), (ss_quantity#3335 >= 1), (ss_quantity#3335 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3345))], output=[avg(ss_net_paid)#3277])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16831]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3345))], output=[sum#3637, count#3638L])
                  +- Project [ss_net_paid#3345]
                     +- Filter ((isnotnull(ss_quantity#3335) AND (ss_quantity#3335 >= 1)) AND (ss_quantity#3335 <= 20))
                        +- FileScan parquet [ss_quantity#3335,ss_net_paid#3345] Batched: true, DataFilters: [isnotnull(ss_quantity#3335), (ss_quantity#3335 >= 1), (ss_quantity#3335 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
   :  :- Subquery subquery#3256, [id=#16846]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3279L])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17201]
                  +- *(1) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3640L])
                     +- *(1) Project
                        +- *(1) Filter ((isnotnull(ss_quantity#3358) AND (ss_quantity#3358 >= 21)) AND (ss_quantity#3358 <= 40))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3358] Batched: true, DataFilters: [isnotnull(ss_quantity#3358), (ss_quantity#3358 >= 21), (ss_quantity#3358 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3279L])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16844]
               +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3640L])
                  +- Project
                     +- Filter ((isnotnull(ss_quantity#3358) AND (ss_quantity#3358 >= 21)) AND (ss_quantity#3358 <= 40))
                        +- FileScan parquet [ss_quantity#3358] Batched: true, DataFilters: [isnotnull(ss_quantity#3358), (ss_quantity#3358 >= 21), (ss_quantity#3358 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int>
   :  :- Subquery subquery#3257, [id=#16859]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3389))], output=[avg(ss_ext_tax)#3281])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17271]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3389))], output=[sum#3643, count#3644L])
                     +- *(1) Project [ss_ext_tax#3389]
                        +- *(1) Filter ((isnotnull(ss_quantity#3381) AND (ss_quantity#3381 >= 21)) AND (ss_quantity#3381 <= 40))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3381,ss_ext_tax#3389] Batched: true, DataFilters: [isnotnull(ss_quantity#3381), (ss_quantity#3381 >= 21), (ss_quantity#3381 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3389))], output=[avg(ss_ext_tax)#3281])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16857]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3389))], output=[sum#3643, count#3644L])
                  +- Project [ss_ext_tax#3389]
                     +- Filter ((isnotnull(ss_quantity#3381) AND (ss_quantity#3381 >= 21)) AND (ss_quantity#3381 <= 40))
                        +- FileScan parquet [ss_quantity#3381,ss_ext_tax#3389] Batched: true, DataFilters: [isnotnull(ss_quantity#3381), (ss_quantity#3381 >= 21), (ss_quantity#3381 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
   :  :- Subquery subquery#3258, [id=#16872]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3414))], output=[avg(ss_net_paid)#3283])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17216]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3414))], output=[sum#3647, count#3648L])
                     +- *(1) Project [ss_net_paid#3414]
                        +- *(1) Filter ((isnotnull(ss_quantity#3404) AND (ss_quantity#3404 >= 21)) AND (ss_quantity#3404 <= 40))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3404,ss_net_paid#3414] Batched: true, DataFilters: [isnotnull(ss_quantity#3404), (ss_quantity#3404 >= 21), (ss_quantity#3404 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3414))], output=[avg(ss_net_paid)#3283])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16870]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3414))], output=[sum#3647, count#3648L])
                  +- Project [ss_net_paid#3414]
                     +- Filter ((isnotnull(ss_quantity#3404) AND (ss_quantity#3404 >= 21)) AND (ss_quantity#3404 <= 40))
                        +- FileScan parquet [ss_quantity#3404,ss_net_paid#3414] Batched: true, DataFilters: [isnotnull(ss_quantity#3404), (ss_quantity#3404 >= 21), (ss_quantity#3404 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
   :  :- Subquery subquery#3260, [id=#16885]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3285L])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17234]
                  +- *(1) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3650L])
                     +- *(1) Project
                        +- *(1) Filter ((isnotnull(ss_quantity#3427) AND (ss_quantity#3427 >= 41)) AND (ss_quantity#3427 <= 60))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3427] Batched: true, DataFilters: [isnotnull(ss_quantity#3427), (ss_quantity#3427 >= 41), (ss_quantity#3427 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3285L])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16883]
               +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3650L])
                  +- Project
                     +- Filter ((isnotnull(ss_quantity#3427) AND (ss_quantity#3427 >= 41)) AND (ss_quantity#3427 <= 60))
                        +- FileScan parquet [ss_quantity#3427] Batched: true, DataFilters: [isnotnull(ss_quantity#3427), (ss_quantity#3427 >= 41), (ss_quantity#3427 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int>
   :  :- Subquery subquery#3261, [id=#16898]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3458))], output=[avg(ss_ext_tax)#3287])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17463]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3458))], output=[sum#3653, count#3654L])
                     +- *(1) Project [ss_ext_tax#3458]
                        +- *(1) Filter ((isnotnull(ss_quantity#3450) AND (ss_quantity#3450 >= 41)) AND (ss_quantity#3450 <= 60))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3450,ss_ext_tax#3458] Batched: true, DataFilters: [isnotnull(ss_quantity#3450), (ss_quantity#3450 >= 41), (ss_quantity#3450 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3458))], output=[avg(ss_ext_tax)#3287])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16896]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3458))], output=[sum#3653, count#3654L])
                  +- Project [ss_ext_tax#3458]
                     +- Filter ((isnotnull(ss_quantity#3450) AND (ss_quantity#3450 >= 41)) AND (ss_quantity#3450 <= 60))
                        +- FileScan parquet [ss_quantity#3450,ss_ext_tax#3458] Batched: true, DataFilters: [isnotnull(ss_quantity#3450), (ss_quantity#3450 >= 41), (ss_quantity#3450 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
   :  :- Subquery subquery#3262, [id=#16911]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3483))], output=[avg(ss_net_paid)#3289])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17287]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3483))], output=[sum#3657, count#3658L])
                     +- *(1) Project [ss_net_paid#3483]
                        +- *(1) Filter ((isnotnull(ss_quantity#3473) AND (ss_quantity#3473 >= 41)) AND (ss_quantity#3473 <= 60))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3473,ss_net_paid#3483] Batched: true, DataFilters: [isnotnull(ss_quantity#3473), (ss_quantity#3473 >= 41), (ss_quantity#3473 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3483))], output=[avg(ss_net_paid)#3289])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16909]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3483))], output=[sum#3657, count#3658L])
                  +- Project [ss_net_paid#3483]
                     +- Filter ((isnotnull(ss_quantity#3473) AND (ss_quantity#3473 >= 41)) AND (ss_quantity#3473 <= 60))
                        +- FileScan parquet [ss_quantity#3473,ss_net_paid#3483] Batched: true, DataFilters: [isnotnull(ss_quantity#3473), (ss_quantity#3473 >= 41), (ss_quantity#3473 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
   :  :- Subquery subquery#3264, [id=#16924]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3291L])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17270]
                  +- *(1) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3660L])
                     +- *(1) Project
                        +- *(1) Filter ((isnotnull(ss_quantity#3496) AND (ss_quantity#3496 >= 61)) AND (ss_quantity#3496 <= 80))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3496] Batched: true, DataFilters: [isnotnull(ss_quantity#3496), (ss_quantity#3496 >= 61), (ss_quantity#3496 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3291L])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16922]
               +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3660L])
                  +- Project
                     +- Filter ((isnotnull(ss_quantity#3496) AND (ss_quantity#3496 >= 61)) AND (ss_quantity#3496 <= 80))
                        +- FileScan parquet [ss_quantity#3496] Batched: true, DataFilters: [isnotnull(ss_quantity#3496), (ss_quantity#3496 >= 61), (ss_quantity#3496 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int>
   :  :- Subquery subquery#3265, [id=#16937]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3527))], output=[avg(ss_ext_tax)#3293])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17300]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3527))], output=[sum#3663, count#3664L])
                     +- *(1) Project [ss_ext_tax#3527]
                        +- *(1) Filter ((isnotnull(ss_quantity#3519) AND (ss_quantity#3519 >= 61)) AND (ss_quantity#3519 <= 80))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3519,ss_ext_tax#3527] Batched: true, DataFilters: [isnotnull(ss_quantity#3519), (ss_quantity#3519 >= 61), (ss_quantity#3519 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3527))], output=[avg(ss_ext_tax)#3293])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16935]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3527))], output=[sum#3663, count#3664L])
                  +- Project [ss_ext_tax#3527]
                     +- Filter ((isnotnull(ss_quantity#3519) AND (ss_quantity#3519 >= 61)) AND (ss_quantity#3519 <= 80))
                        +- FileScan parquet [ss_quantity#3519,ss_ext_tax#3527] Batched: true, DataFilters: [isnotnull(ss_quantity#3519), (ss_quantity#3519 >= 61), (ss_quantity#3519 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
   :  :- Subquery subquery#3266, [id=#16950]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3552))], output=[avg(ss_net_paid)#3295])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17333]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3552))], output=[sum#3667, count#3668L])
                     +- *(1) Project [ss_net_paid#3552]
                        +- *(1) Filter ((isnotnull(ss_quantity#3542) AND (ss_quantity#3542 >= 61)) AND (ss_quantity#3542 <= 80))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3542,ss_net_paid#3552] Batched: true, DataFilters: [isnotnull(ss_quantity#3542), (ss_quantity#3542 >= 61), (ss_quantity#3542 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3552))], output=[avg(ss_net_paid)#3295])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16948]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3552))], output=[sum#3667, count#3668L])
                  +- Project [ss_net_paid#3552]
                     +- Filter ((isnotnull(ss_quantity#3542) AND (ss_quantity#3542 >= 61)) AND (ss_quantity#3542 <= 80))
                        +- FileScan parquet [ss_quantity#3542,ss_net_paid#3552] Batched: true, DataFilters: [isnotnull(ss_quantity#3542), (ss_quantity#3542 >= 61), (ss_quantity#3542 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
   :  :- Subquery subquery#3268, [id=#16963]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3297L])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17336]
                  +- *(1) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3670L])
                     +- *(1) Project
                        +- *(1) Filter ((isnotnull(ss_quantity#3565) AND (ss_quantity#3565 >= 81)) AND (ss_quantity#3565 <= 100))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3565] Batched: true, DataFilters: [isnotnull(ss_quantity#3565), (ss_quantity#3565 >= 81), (ss_quantity#3565 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3297L])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16961]
               +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3670L])
                  +- Project
                     +- Filter ((isnotnull(ss_quantity#3565) AND (ss_quantity#3565 >= 81)) AND (ss_quantity#3565 <= 100))
                        +- FileScan parquet [ss_quantity#3565] Batched: true, DataFilters: [isnotnull(ss_quantity#3565), (ss_quantity#3565 >= 81), (ss_quantity#3565 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int>
   :  :- Subquery subquery#3269, [id=#16976]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3596))], output=[avg(ss_ext_tax)#3299])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17454]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3596))], output=[sum#3673, count#3674L])
                     +- *(1) Project [ss_ext_tax#3596]
                        +- *(1) Filter ((isnotnull(ss_quantity#3588) AND (ss_quantity#3588 >= 81)) AND (ss_quantity#3588 <= 100))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3588,ss_ext_tax#3596] Batched: true, DataFilters: [isnotnull(ss_quantity#3588), (ss_quantity#3588 >= 81), (ss_quantity#3588 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3596))], output=[avg(ss_ext_tax)#3299])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16974]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3596))], output=[sum#3673, count#3674L])
                  +- Project [ss_ext_tax#3596]
                     +- Filter ((isnotnull(ss_quantity#3588) AND (ss_quantity#3588 >= 81)) AND (ss_quantity#3588 <= 100))
                        +- FileScan parquet [ss_quantity#3588,ss_ext_tax#3596] Batched: true, DataFilters: [isnotnull(ss_quantity#3588), (ss_quantity#3588 >= 81), (ss_quantity#3588 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
   :  +- Subquery subquery#3270, [id=#16989]
   :     +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3621))], output=[avg(ss_net_paid)#3301])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17460]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3621))], output=[sum#3677, count#3678L])
                     +- *(1) Project [ss_net_paid#3621]
                        +- *(1) Filter ((isnotnull(ss_quantity#3611) AND (ss_quantity#3611 >= 81)) AND (ss_quantity#3611 <= 100))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3611,ss_net_paid#3621] Batched: true, DataFilters: [isnotnull(ss_quantity#3611), (ss_quantity#3611 >= 81), (ss_quantity#3611 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3621))], output=[avg(ss_net_paid)#3301])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16987]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3621))], output=[sum#3677, count#3678L])
                  +- Project [ss_net_paid#3621]
                     +- Filter ((isnotnull(ss_quantity#3611) AND (ss_quantity#3611 >= 81)) AND (ss_quantity#3611 <= 100))
                        +- FileScan parquet [ss_quantity#3611,ss_net_paid#3621] Batched: true, DataFilters: [isnotnull(ss_quantity#3611), (ss_quantity#3611 >= 81), (ss_quantity#3611 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
   +- *(1) Filter (isnotnull(r_reason_sk#246) AND (r_reason_sk#246 = 1))
      +- *(1) ColumnarToRow
         +- FileScan parquet [r_reason_sk#246] Batched: true, DataFilters: [isnotnull(r_reason_sk#246), (r_reason_sk#246 = 1)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/reason.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(r_reason_sk), EqualTo(r_reason_sk,1)], ReadSchema: struct<r_reason_sk:int>
+- == Initial Plan ==
   Project [CASE WHEN (Subquery subquery#3252, [id=#16807] > 409437) THEN Subquery subquery#3253, [id=#16820] ELSE Subquery subquery#3254, [id=#16833] END AS bucket1#3255, CASE WHEN (Subquery subquery#3256, [id=#16846] > 4595804) THEN Subquery subquery#3257, [id=#16859] ELSE Subquery subquery#3258, [id=#16872] END AS bucket2#3259, CASE WHEN (Subquery subquery#3260, [id=#16885] > 1333710) THEN Subquery subquery#3261, [id=#16898] ELSE Subquery subquery#3262, [id=#16911] END AS bucket3#3263, CASE WHEN (Subquery subquery#3264, [id=#16924] > 2361102) THEN Subquery subquery#3265, [id=#16937] ELSE Subquery subquery#3266, [id=#16950] END AS bucket4#3267, CASE WHEN (Subquery subquery#3268, [id=#16963] > 1517817) THEN Subquery subquery#3269, [id=#16976] ELSE Subquery subquery#3270, [id=#16989] END AS bucket5#3271]
   :  :- Subquery subquery#3252, [id=#16807]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3273L])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17212]
                  +- *(1) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3630L])
                     +- *(1) Project
                        +- *(1) Filter ((isnotnull(ss_quantity#262) AND (ss_quantity#262 >= 1)) AND (ss_quantity#262 <= 20))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#262] Batched: true, DataFilters: [isnotnull(ss_quantity#262), (ss_quantity#262 >= 1), (ss_quantity#262 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3273L])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16805]
               +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3630L])
                  +- Project
                     +- Filter ((isnotnull(ss_quantity#262) AND (ss_quantity#262 >= 1)) AND (ss_quantity#262 <= 20))
                        +- FileScan parquet [ss_quantity#262] Batched: true, DataFilters: [isnotnull(ss_quantity#262), (ss_quantity#262 >= 1), (ss_quantity#262 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int>
   :  :- Subquery subquery#3253, [id=#16820]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3320))], output=[avg(ss_ext_tax)#3275])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17180]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3320))], output=[sum#3633, count#3634L])
                     +- *(1) Project [ss_ext_tax#3320]
                        +- *(1) Filter ((isnotnull(ss_quantity#3312) AND (ss_quantity#3312 >= 1)) AND (ss_quantity#3312 <= 20))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3312,ss_ext_tax#3320] Batched: true, DataFilters: [isnotnull(ss_quantity#3312), (ss_quantity#3312 >= 1), (ss_quantity#3312 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3320))], output=[avg(ss_ext_tax)#3275])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16818]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3320))], output=[sum#3633, count#3634L])
                  +- Project [ss_ext_tax#3320]
                     +- Filter ((isnotnull(ss_quantity#3312) AND (ss_quantity#3312 >= 1)) AND (ss_quantity#3312 <= 20))
                        +- FileScan parquet [ss_quantity#3312,ss_ext_tax#3320] Batched: true, DataFilters: [isnotnull(ss_quantity#3312), (ss_quantity#3312 >= 1), (ss_quantity#3312 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
   :  :- Subquery subquery#3254, [id=#16833]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3345))], output=[avg(ss_net_paid)#3277])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17168]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3345))], output=[sum#3637, count#3638L])
                     +- *(1) Project [ss_net_paid#3345]
                        +- *(1) Filter ((isnotnull(ss_quantity#3335) AND (ss_quantity#3335 >= 1)) AND (ss_quantity#3335 <= 20))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3335,ss_net_paid#3345] Batched: true, DataFilters: [isnotnull(ss_quantity#3335), (ss_quantity#3335 >= 1), (ss_quantity#3335 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3345))], output=[avg(ss_net_paid)#3277])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16831]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3345))], output=[sum#3637, count#3638L])
                  +- Project [ss_net_paid#3345]
                     +- Filter ((isnotnull(ss_quantity#3335) AND (ss_quantity#3335 >= 1)) AND (ss_quantity#3335 <= 20))
                        +- FileScan parquet [ss_quantity#3335,ss_net_paid#3345] Batched: true, DataFilters: [isnotnull(ss_quantity#3335), (ss_quantity#3335 >= 1), (ss_quantity#3335 <= 20)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,1), LessThanOrEqual(ss_quantity,20)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
   :  :- Subquery subquery#3256, [id=#16846]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3279L])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17201]
                  +- *(1) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3640L])
                     +- *(1) Project
                        +- *(1) Filter ((isnotnull(ss_quantity#3358) AND (ss_quantity#3358 >= 21)) AND (ss_quantity#3358 <= 40))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3358] Batched: true, DataFilters: [isnotnull(ss_quantity#3358), (ss_quantity#3358 >= 21), (ss_quantity#3358 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3279L])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16844]
               +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3640L])
                  +- Project
                     +- Filter ((isnotnull(ss_quantity#3358) AND (ss_quantity#3358 >= 21)) AND (ss_quantity#3358 <= 40))
                        +- FileScan parquet [ss_quantity#3358] Batched: true, DataFilters: [isnotnull(ss_quantity#3358), (ss_quantity#3358 >= 21), (ss_quantity#3358 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int>
   :  :- Subquery subquery#3257, [id=#16859]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3389))], output=[avg(ss_ext_tax)#3281])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17271]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3389))], output=[sum#3643, count#3644L])
                     +- *(1) Project [ss_ext_tax#3389]
                        +- *(1) Filter ((isnotnull(ss_quantity#3381) AND (ss_quantity#3381 >= 21)) AND (ss_quantity#3381 <= 40))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3381,ss_ext_tax#3389] Batched: true, DataFilters: [isnotnull(ss_quantity#3381), (ss_quantity#3381 >= 21), (ss_quantity#3381 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3389))], output=[avg(ss_ext_tax)#3281])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16857]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3389))], output=[sum#3643, count#3644L])
                  +- Project [ss_ext_tax#3389]
                     +- Filter ((isnotnull(ss_quantity#3381) AND (ss_quantity#3381 >= 21)) AND (ss_quantity#3381 <= 40))
                        +- FileScan parquet [ss_quantity#3381,ss_ext_tax#3389] Batched: true, DataFilters: [isnotnull(ss_quantity#3381), (ss_quantity#3381 >= 21), (ss_quantity#3381 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
   :  :- Subquery subquery#3258, [id=#16872]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3414))], output=[avg(ss_net_paid)#3283])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17216]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3414))], output=[sum#3647, count#3648L])
                     +- *(1) Project [ss_net_paid#3414]
                        +- *(1) Filter ((isnotnull(ss_quantity#3404) AND (ss_quantity#3404 >= 21)) AND (ss_quantity#3404 <= 40))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3404,ss_net_paid#3414] Batched: true, DataFilters: [isnotnull(ss_quantity#3404), (ss_quantity#3404 >= 21), (ss_quantity#3404 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3414))], output=[avg(ss_net_paid)#3283])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16870]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3414))], output=[sum#3647, count#3648L])
                  +- Project [ss_net_paid#3414]
                     +- Filter ((isnotnull(ss_quantity#3404) AND (ss_quantity#3404 >= 21)) AND (ss_quantity#3404 <= 40))
                        +- FileScan parquet [ss_quantity#3404,ss_net_paid#3414] Batched: true, DataFilters: [isnotnull(ss_quantity#3404), (ss_quantity#3404 >= 21), (ss_quantity#3404 <= 40)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,21), LessThanOrEqual(ss_quantity,40)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
   :  :- Subquery subquery#3260, [id=#16885]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3285L])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17234]
                  +- *(1) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3650L])
                     +- *(1) Project
                        +- *(1) Filter ((isnotnull(ss_quantity#3427) AND (ss_quantity#3427 >= 41)) AND (ss_quantity#3427 <= 60))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3427] Batched: true, DataFilters: [isnotnull(ss_quantity#3427), (ss_quantity#3427 >= 41), (ss_quantity#3427 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3285L])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16883]
               +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3650L])
                  +- Project
                     +- Filter ((isnotnull(ss_quantity#3427) AND (ss_quantity#3427 >= 41)) AND (ss_quantity#3427 <= 60))
                        +- FileScan parquet [ss_quantity#3427] Batched: true, DataFilters: [isnotnull(ss_quantity#3427), (ss_quantity#3427 >= 41), (ss_quantity#3427 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int>
   :  :- Subquery subquery#3261, [id=#16898]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3458))], output=[avg(ss_ext_tax)#3287])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17463]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3458))], output=[sum#3653, count#3654L])
                     +- *(1) Project [ss_ext_tax#3458]
                        +- *(1) Filter ((isnotnull(ss_quantity#3450) AND (ss_quantity#3450 >= 41)) AND (ss_quantity#3450 <= 60))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3450,ss_ext_tax#3458] Batched: true, DataFilters: [isnotnull(ss_quantity#3450), (ss_quantity#3450 >= 41), (ss_quantity#3450 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3458))], output=[avg(ss_ext_tax)#3287])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16896]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3458))], output=[sum#3653, count#3654L])
                  +- Project [ss_ext_tax#3458]
                     +- Filter ((isnotnull(ss_quantity#3450) AND (ss_quantity#3450 >= 41)) AND (ss_quantity#3450 <= 60))
                        +- FileScan parquet [ss_quantity#3450,ss_ext_tax#3458] Batched: true, DataFilters: [isnotnull(ss_quantity#3450), (ss_quantity#3450 >= 41), (ss_quantity#3450 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
   :  :- Subquery subquery#3262, [id=#16911]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3483))], output=[avg(ss_net_paid)#3289])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17287]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3483))], output=[sum#3657, count#3658L])
                     +- *(1) Project [ss_net_paid#3483]
                        +- *(1) Filter ((isnotnull(ss_quantity#3473) AND (ss_quantity#3473 >= 41)) AND (ss_quantity#3473 <= 60))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3473,ss_net_paid#3483] Batched: true, DataFilters: [isnotnull(ss_quantity#3473), (ss_quantity#3473 >= 41), (ss_quantity#3473 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3483))], output=[avg(ss_net_paid)#3289])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16909]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3483))], output=[sum#3657, count#3658L])
                  +- Project [ss_net_paid#3483]
                     +- Filter ((isnotnull(ss_quantity#3473) AND (ss_quantity#3473 >= 41)) AND (ss_quantity#3473 <= 60))
                        +- FileScan parquet [ss_quantity#3473,ss_net_paid#3483] Batched: true, DataFilters: [isnotnull(ss_quantity#3473), (ss_quantity#3473 >= 41), (ss_quantity#3473 <= 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,41), LessThanOrEqual(ss_quantity,60)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
   :  :- Subquery subquery#3264, [id=#16924]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3291L])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17270]
                  +- *(1) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3660L])
                     +- *(1) Project
                        +- *(1) Filter ((isnotnull(ss_quantity#3496) AND (ss_quantity#3496 >= 61)) AND (ss_quantity#3496 <= 80))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3496] Batched: true, DataFilters: [isnotnull(ss_quantity#3496), (ss_quantity#3496 >= 61), (ss_quantity#3496 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3291L])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16922]
               +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3660L])
                  +- Project
                     +- Filter ((isnotnull(ss_quantity#3496) AND (ss_quantity#3496 >= 61)) AND (ss_quantity#3496 <= 80))
                        +- FileScan parquet [ss_quantity#3496] Batched: true, DataFilters: [isnotnull(ss_quantity#3496), (ss_quantity#3496 >= 61), (ss_quantity#3496 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int>
   :  :- Subquery subquery#3265, [id=#16937]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3527))], output=[avg(ss_ext_tax)#3293])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17300]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3527))], output=[sum#3663, count#3664L])
                     +- *(1) Project [ss_ext_tax#3527]
                        +- *(1) Filter ((isnotnull(ss_quantity#3519) AND (ss_quantity#3519 >= 61)) AND (ss_quantity#3519 <= 80))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3519,ss_ext_tax#3527] Batched: true, DataFilters: [isnotnull(ss_quantity#3519), (ss_quantity#3519 >= 61), (ss_quantity#3519 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3527))], output=[avg(ss_ext_tax)#3293])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16935]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3527))], output=[sum#3663, count#3664L])
                  +- Project [ss_ext_tax#3527]
                     +- Filter ((isnotnull(ss_quantity#3519) AND (ss_quantity#3519 >= 61)) AND (ss_quantity#3519 <= 80))
                        +- FileScan parquet [ss_quantity#3519,ss_ext_tax#3527] Batched: true, DataFilters: [isnotnull(ss_quantity#3519), (ss_quantity#3519 >= 61), (ss_quantity#3519 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
   :  :- Subquery subquery#3266, [id=#16950]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3552))], output=[avg(ss_net_paid)#3295])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17333]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3552))], output=[sum#3667, count#3668L])
                     +- *(1) Project [ss_net_paid#3552]
                        +- *(1) Filter ((isnotnull(ss_quantity#3542) AND (ss_quantity#3542 >= 61)) AND (ss_quantity#3542 <= 80))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3542,ss_net_paid#3552] Batched: true, DataFilters: [isnotnull(ss_quantity#3542), (ss_quantity#3542 >= 61), (ss_quantity#3542 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3552))], output=[avg(ss_net_paid)#3295])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16948]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3552))], output=[sum#3667, count#3668L])
                  +- Project [ss_net_paid#3552]
                     +- Filter ((isnotnull(ss_quantity#3542) AND (ss_quantity#3542 >= 61)) AND (ss_quantity#3542 <= 80))
                        +- FileScan parquet [ss_quantity#3542,ss_net_paid#3552] Batched: true, DataFilters: [isnotnull(ss_quantity#3542), (ss_quantity#3542 >= 61), (ss_quantity#3542 <= 80)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,61), LessThanOrEqual(ss_quantity,80)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
   :  :- Subquery subquery#3268, [id=#16963]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3297L])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17336]
                  +- *(1) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3670L])
                     +- *(1) Project
                        +- *(1) Filter ((isnotnull(ss_quantity#3565) AND (ss_quantity#3565 >= 81)) AND (ss_quantity#3565 <= 100))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3565] Batched: true, DataFilters: [isnotnull(ss_quantity#3565), (ss_quantity#3565 >= 81), (ss_quantity#3565 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[count(1)], output=[count(1)#3297L])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16961]
               +- HashAggregate(keys=[], functions=[partial_count(1)], output=[count#3670L])
                  +- Project
                     +- Filter ((isnotnull(ss_quantity#3565) AND (ss_quantity#3565 >= 81)) AND (ss_quantity#3565 <= 100))
                        +- FileScan parquet [ss_quantity#3565] Batched: true, DataFilters: [isnotnull(ss_quantity#3565), (ss_quantity#3565 >= 81), (ss_quantity#3565 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int>
   :  :- Subquery subquery#3269, [id=#16976]
   :  :  +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3596))], output=[avg(ss_ext_tax)#3299])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17454]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3596))], output=[sum#3673, count#3674L])
                     +- *(1) Project [ss_ext_tax#3596]
                        +- *(1) Filter ((isnotnull(ss_quantity#3588) AND (ss_quantity#3588 >= 81)) AND (ss_quantity#3588 <= 100))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3588,ss_ext_tax#3596] Batched: true, DataFilters: [isnotnull(ss_quantity#3588), (ss_quantity#3588 >= 81), (ss_quantity#3588 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_ext_tax#3596))], output=[avg(ss_ext_tax)#3299])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16974]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_ext_tax#3596))], output=[sum#3673, count#3674L])
                  +- Project [ss_ext_tax#3596]
                     +- Filter ((isnotnull(ss_quantity#3588) AND (ss_quantity#3588 >= 81)) AND (ss_quantity#3588 <= 100))
                        +- FileScan parquet [ss_quantity#3588,ss_ext_tax#3596] Batched: true, DataFilters: [isnotnull(ss_quantity#3588), (ss_quantity#3588 >= 81), (ss_quantity#3588 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int,ss_ext_tax:decimal(7,2)>
   :  +- Subquery subquery#3270, [id=#16989]
   :     +- AdaptiveSparkPlan isFinalPlan=true
         +- == Final Plan ==
            *(2) HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3621))], output=[avg(ss_net_paid)#3301])
            +- ShuffleQueryStage 0
               +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#17460]
                  +- *(1) HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3621))], output=[sum#3677, count#3678L])
                     +- *(1) Project [ss_net_paid#3621]
                        +- *(1) Filter ((isnotnull(ss_quantity#3611) AND (ss_quantity#3611 >= 81)) AND (ss_quantity#3611 <= 100))
                           +- *(1) ColumnarToRow
                              +- FileScan parquet [ss_quantity#3611,ss_net_paid#3621] Batched: true, DataFilters: [isnotnull(ss_quantity#3611), (ss_quantity#3611 >= 81), (ss_quantity#3611 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
         +- == Initial Plan ==
            HashAggregate(keys=[], functions=[avg(UnscaledValue(ss_net_paid#3621))], output=[avg(ss_net_paid)#3301])
            +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#16987]
               +- HashAggregate(keys=[], functions=[partial_avg(UnscaledValue(ss_net_paid#3621))], output=[sum#3677, count#3678L])
                  +- Project [ss_net_paid#3621]
                     +- Filter ((isnotnull(ss_quantity#3611) AND (ss_quantity#3611 >= 81)) AND (ss_quantity#3611 <= 100))
                        +- FileScan parquet [ss_quantity#3611,ss_net_paid#3621] Batched: true, DataFilters: [isnotnull(ss_quantity#3611), (ss_quantity#3611 >= 81), (ss_quantity#3611 <= 100)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/store_sales.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(ss_quantity), GreaterThanOrEqual(ss_quantity,81), LessThanOrEqual(ss_quantity,100)], ReadSchema: struct<ss_quantity:int,ss_net_paid:decimal(7,2)>
   +- Filter (isnotnull(r_reason_sk#246) AND (r_reason_sk#246 = 1))
      +- FileScan parquet [r_reason_sk#246] Batched: true, DataFilters: [isnotnull(r_reason_sk#246), (r_reason_sk#246 = 1)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/mnt/bigdata/tpcds/sf100-parquet/reason.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(r_reason_sk), EqualTo(r_reason_sk,1)], ReadSchema: struct<r_reason_sk:int>
